version: '3.8'  # Specifies the version of the Docker Compose file format. '3.8' is a modern version.

# 'x-*' fields are a YAML feature for creating reusable blocks, called "anchors".
x-airflow-common: &airflow-common  # This block, named '&airflow-common', defines a common configuration for all Airflow services.
  build: .  # Build the image from the Dockerfile in the current directory
  # image: apache/airflow:2.7.3  # The Docker image to use for the service. This pulls a specific version of Airflow.
  environment:  # Environment variables set inside the container, used to configure Airflow.
    - AIRFLOW_HOME=/opt/airflow # Explicitly set the Airflow home directory
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor  # Specifies the executor. LocalExecutor runs tasks sequentially on the same machine.
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow  # The connection string for the metadata database. Tells Airflow to use a 'postgres' service.
    - AIRFLOW__CORE__FERNET_KEY=r3PLbX8P92O1x_FzB5EacbnxN3gBq-u-aYw4a_zFpZg=  # A secret key used to encrypt connection credentials and other sensitive data.
    - AIRFLOW__CORE__LOAD_EXAMPLES=False  # Prevents Airflow from loading a large set of example DAGs.
    - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth  # Enables basic authentication (username/password) for the Airflow API and UI.
  volumes:  # 'volumes' mount local directories into the container, creating a live link.
    - ./dags:/opt/airflow/dags  # Maps the local 'dags' folder to the DAGs folder inside the container.
    - ./logs:/opt/airflow/logs # Add a shared volume for logs
    - ./src:/opt/airflow/src  # Maps your project's source code so the DAG can import custom modules.
    - ./config:/opt/airflow/config  # Maps your project's configuration.
    - ./outputs:/opt/airflow/outputs  # Maps the outputs folder to persist reports and data generated by the DAG.
    - ./requirements.txt:/opt/airflow/requirements.txt  # Maps the requirements file so it can be installed inside the container.
  user: "${AIRFLOW_UID:-50000}"  # Sets the user inside the container to avoid file permission issues.

services:  # The 'services' section defines the individual containers that make up the application.
  postgres:  # Defines the PostgreSQL database service.
    image: postgres:13  # The Docker image for the database.
    container_name: postgres  # A friendly name for the container.
    environment:  # Environment variables to configure the PostgreSQL container.
      - POSTGRES_USER=airflow  # Must match the user in the Airflow connection string.
      - POSTGRES_PASSWORD=airflow  # Must match the password in the Airflow connection string.
      - POSTGRES_DB=airflow  # Must match the database name in the Airflow connection string.
    volumes:  # A named volume to persist database data even if the container is removed.
      - postgres-db-volume:/var/lib/postgresql/data
    ports:  # Maps port 5432 on the host to 5432 in the container (optional, for external access).
      - "5432:5432"
    healthcheck:  # A healthcheck ensures other services only start after the database is truly ready.
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  airflow-webserver:  # Defines the Airflow webserver service, which runs the UI.
    <<: *airflow-common  # '<<: *airflow-common' inherits all properties from the 'airflow-common' template.
    container_name: airflow-webserver
    command: webserver  # Overrides the default command to start the webserver process.
    ports:  # Maps port 8080 on the host to 8080 in the container to make the UI accessible.
      - "8080:8080"
    depends_on:  # Controls the startup order.
      postgres:
        condition: service_healthy  # Waits for the postgres healthcheck to pass.
      airflow-init:
        condition: service_completed_successfully  # Waits for the init service to finish.
    restart: always  # Automatically restarts the container if it crashes.

  airflow-scheduler:  # Defines the Airflow scheduler, the core component that triggers DAG runs.
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler  # Overrides the default command to start the scheduler process.
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    restart: always

  airflow-init:  # A special one-time service to initialize the Airflow environment.
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash  # Sets the container's entrypoint to bash.
    command:  # The command to run. '-c' tells bash to execute the following script.
      - -c
      - |
        # 1. Install all python packages from your project's requirements file.
        pip install -r /opt/airflow/requirements.txt
        # 2. Initialize the Airflow metadata database.
        airflow db init
        # 3. Create the default admin user for the UI.
        airflow users create --username admin --firstname Tamara --lastname Markachevikj --role Admin --email markacevic@gmail.com --password admin

volumes:  # Defines the named volumes used by the services.
  postgres-db-volume:  # This volume is managed by Docker to persist the PostgreSQL database data.